FROM apache/airflow:3.0.3-python3.10 AS airflow_base

#RUN apt-get update 

FROM airflow_base AS airflow_spark

USER root

# Atualiza pacotes e instala dependências
RUN apt-get update && \
    apt-get install -y curl wget openjdk-17-jre-headless procps && \
    apt-get clean

# Baixa e instala o Spark 3.5.4
RUN wget -q https://archive.apache.org/dist/spark/spark-3.5.4/spark-3.5.4-bin-hadoop3.tgz -O spark.tgz && \
    tar -xzf spark.tgz && \
    mv spark-3.5.4-bin-hadoop3 /opt/spark && \
    rm spark.tgz


# Define variáveis de ambiente
ENV SPARK_HOME=/opt/spark
ENV PATH=$SPARK_HOME/bin:$PATH
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64


FROM airflow_spark AS airflow_providers

USER airflow

RUN pip install --no-cache-dir apache-airflow-providers-apache-spark pyspark==3.5.4


FROM airflow_providers AS airflow_requirements

COPY requirements.txt .

RUN pip install --no-cache-dir -r requirements.txt

